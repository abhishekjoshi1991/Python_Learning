{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are mainly two ways to extract data from a website:\n",
    "\n",
    "#### Use the API of the website (if it exists). For example, Facebook has the Facebook Graph API which allows retrieval of data posted on Facebook.\n",
    "\n",
    "#### Access the HTML of the webpage and extract useful information/data from it. This technique is called web scraping or web harvesting or web data extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Through beautiful soup we can access the HTML code of webpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Once we have accessed the HTML content, we have to do task of parsing the data.\n",
    "\n",
    "#### Since most of the HTML data is nested, we cannot extract data simply through string processing. We needs a parser which can create a nested/tree structure of the HTML data.\n",
    "\n",
    "#### Then all we need to do is navigating and searching the parse tree that we created, i.e. tree traversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's extract data from HTML code of webpage \"http://dataquestio.github.io/web-scraping-pages/simple.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup   #for beautiful soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('http://dataquestio.github.io/web-scraping-pages/simple.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<html>\\n    <head>\\n        <title>A simple example page</title>\\n    </head>\\n    <body>\\n        <p>Here is some simple content for this page.</p>\\n    </body>\\n</html>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now using requests library we get some unstructured data, like above. BS4 library used to convert it into something structured one and allows us to parse data from HTML page of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.content, 'html.parser')  #r.content or r.text, and html.parser not required may be\n",
    "\n",
    "#we can also parse as lxml instead of html.parser, for that we need to install lxml library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "\n",
       "<html>\n",
       "<head>\n",
       "<title>A simple example page</title>\n",
       "</head>\n",
       "<body>\n",
       "<p>Here is some simple content for this page.</p>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup  #got soup object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   A simple example page\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p>\n",
      "   Here is some simple content for this page.\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())  #gives more like html structure with indentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<list_iterator at 0x229d2718288>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.children  #this gives iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now after running for loop on soup.children we get list of 3 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['html',\n",
       " '\\n',\n",
       " <html>\n",
       " <head>\n",
       " <title>A simple example page</title>\n",
       " </head>\n",
       " <body>\n",
       " <p>Here is some simple content for this page.</p>\n",
       " </body>\n",
       " </html>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in soup.children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in soup.children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[bs4.element.Doctype, bs4.element.NavigableString, bs4.element.Tag]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[type(x) for x in soup.children]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So above, first element of list is main parent element here is DocType, second element is navigable string which is all other than tags in html so here it is \\n , and last element is html tag object (which is child of DocType we can say)\n",
    "\n",
    "#### Means it gives o/p as doctype, naviagable string, html tag\n",
    "\n",
    "#### so we are interested in last element at index -1 of the list, which is HTML tag object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = list(soup.children)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title>A simple example page</title>\n",
       "</head>\n",
       "<body>\n",
       "<p>Here is some simple content for this page.</p>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html #here we will get only html tag now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Again we can run soup.children on this html to deep dive into other tags, like head and body tags etc. In this way we can parse theough the html code\n",
    "\n",
    "#### when we parse through html variable, we will get now \\n, head tag, \\n, body tag, \\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in html.children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " <head>\n",
       " <title>A simple example page</title>\n",
       " </head>,\n",
       " '\\n',\n",
       " <body>\n",
       " <p>Here is some simple content for this page.</p>\n",
       " </body>,\n",
       " '\\n']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in html.children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[bs4.element.NavigableString,\n",
       " bs4.element.Tag,\n",
       " bs4.element.NavigableString,\n",
       " bs4.element.Tag,\n",
       " bs4.element.NavigableString]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[type(x) for x in html.children]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now if we are interested in head tag, we need to use first index position where head tag is present, Let's see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = list(html.children)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<head>\n",
       "<title>A simple example page</title>\n",
       "</head>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n', <title>A simple example page</title>, '\\n']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in head.children]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now if we are interested in title tag, we need to use again first index position where title tag is present, Let's see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = list(head.children)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>A simple example page</title>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A simple example page']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now title tag has not any children left, so we are now fetching text \n",
    "# inside title tag using title.children, instead we will use title.getText()\n",
    "\n",
    "#lets see what we will get after title.children \n",
    "[x for x in title.children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A simple example page'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title.getText() # this is correct way to fetch the text, if tag does not left with childs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If we need to fetch the content in body tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = list(html.children)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body>\n",
       "<p>Here is some simple content for this page.</p>\n",
       "</body>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n', <p>Here is some simple content for this page.</p>, '\\n']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in body.children] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = list(body.children)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>Here is some simple content for this page.</p>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is some simple content for this page.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph.getText()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But this is easy for webpages having simple HTML code, but for big sites it not possible to deep dive like explained above, so we need to use following steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instead of scraping data using html, body, title tags etc., we can use id and classes from HTML code to fetch the data, because this id and classses are permanent for dynamic web pages only content will change. Our script won't work only if site html code is changed wholly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's scrape the data from site \n",
    "# 'https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41963999999996#.YDyJImgzZPY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = requests.get('https://forecast.weather.gov/MapClick.php?lat=32.7157&lon=-117.1617#.YDypH2gzZPY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(data.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now from page's HTML code, we will extract id=\"seven-day-forecast\" to see data relevant to only that div tag\n",
    "# as there is only one id named seven-day-forecast, we will use find method on soup object\n",
    "\n",
    "seven_day = soup.find(id='seven-day-forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now each period for forecast is grabbed under the class=\"tombstone-container\", we will now search data from this class\n",
    "# As there are multiple class with name tombstone-container we will use find_all method\n",
    "\n",
    "forecast_items = seven_day.find_all(class_=\"tombstone-container\") #we use class_ to differentiate from class symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"tombstone-container\">\n",
      " <p class=\"period-name\">\n",
      "  Overnight\n",
      "  <br/>\n",
      "  <br/>\n",
      " </p>\n",
      " <p>\n",
      "  <img alt=\"Overnight: Patchy drizzle with a chance of showers.  Cloudy, with a low around 55. West wind around 5 mph.  Chance of precipitation is 30%. New precipitation amounts of less than a tenth of an inch possible. \" class=\"forecast-icon\" src=\"newimages/medium/nshra30.png\" title=\"Overnight: Patchy drizzle with a chance of showers.  Cloudy, with a low around 55. West wind around 5 mph.  Chance of precipitation is 30%. New precipitation amounts of less than a tenth of an inch possible. \"/>\n",
      " </p>\n",
      " <p class=\"short-desc\">\n",
      "  Chance\n",
      "  <br/>\n",
      "  Showers\n",
      " </p>\n",
      " <p class=\"temp temp-low\">\n",
      "  Low: 55 °F\n",
      " </p>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "# if we are interested only in tonight forecast, we need to use zeroth index of forecast_items list\n",
    "\n",
    "tonight = forecast_items[0]\n",
    "print(tonight.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now from above class of \"tombstone-container\" for tonight, we will grab class=\"period-name\", class=\"short-desc\", class=\"temp temp-low\" and from img tag we will grab the title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = tonight.find(class_=\"period-name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_desc = tonight.find(class_=\"short-desc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = tonight.find(class_=\"temp temp-low\")  #'temp temp-low' or only 'temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overnight\n",
      "ChanceShowers\n",
      "Low: 55 °F\n"
     ]
    }
   ],
   "source": [
    "print(period.get_text())\n",
    "print(short_desc.get_text())\n",
    "print(temperature.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tonight.find(\"img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = image['title']  #image act as dictionary, we can call keys for this just like we do in dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overnight: Patchy drizzle with a chance of showers.  Cloudy, with a low around 55. West wind around 5 mph.  Chance of precipitation is 30%. New precipitation amounts of less than a tenth of an inch possible. \n"
     ]
    }
   ],
   "source": [
    "print(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overnight\n",
      "ChanceShowers\n",
      "Low: 55 °F\n",
      "Overnight: Patchy drizzle with a chance of showers.  Cloudy, with a low around 55. West wind around 5 mph.  Chance of precipitation is 30%. New precipitation amounts of less than a tenth of an inch possible. \n",
      "\n",
      "\n",
      "Monday\n",
      "PatchyDrizzle thenPartly Sunny\n",
      "High: 63 °F\n",
      "Monday: Patchy drizzle with a slight chance of showers before 10am.  Cloudy, then gradually becoming mostly sunny, with a high near 63. West wind 5 to 10 mph.  Chance of precipitation is 20%.\n",
      "\n",
      "\n",
      "MondayNight\n",
      "Mostly Cloudy\n",
      "Low: 52 °F\n",
      "Monday Night: Mostly cloudy, with a low around 52. Northwest wind around 5 mph. \n",
      "\n",
      "\n",
      "Tuesday\n",
      "Partly Sunny\n",
      "High: 60 °F\n",
      "Tuesday: Partly sunny, with a high near 60. West wind 5 to 15 mph, with gusts as high as 20 mph. \n",
      "\n",
      "\n",
      "TuesdayNight\n",
      "Slight ChanceRain thenRain Likely\n",
      "Low: 50 °F\n",
      "Tuesday Night: Rain likely, mainly after 4am.  Mostly cloudy, with a low around 50. West wind around 10 mph, with gusts as high as 20 mph.  Chance of precipitation is 60%. New precipitation amounts between a tenth and quarter of an inch possible. \n",
      "\n",
      "\n",
      "Wednesday\n",
      "Rain\n",
      "High: 58 °F\n",
      "Wednesday: Rain likely, then rain and possibly a thunderstorm after 10am.  High near 58. Chance of precipitation is 80%.\n",
      "\n",
      "\n",
      "WednesdayNight\n",
      "ShowersLikely\n",
      "Low: 46 °F\n",
      "Wednesday Night: Rain likely and possibly a thunderstorm before 10pm, then showers likely and possibly a thunderstorm after 10pm.  Mostly cloudy, with a low around 46. Chance of precipitation is 70%.\n",
      "\n",
      "\n",
      "Thursday\n",
      "ChanceShowers\n",
      "High: 58 °F\n",
      "Thursday: A chance of showers and thunderstorms.  Partly sunny, with a high near 58.\n",
      "\n",
      "\n",
      "ThursdayNight\n",
      "ChanceShowers\n",
      "Low: 45 °F\n",
      "Thursday Night: A chance of showers and thunderstorms before 10pm, then a slight chance of showers.  Partly cloudy, with a low around 45.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we can run for loop also to grab all data for all periods\n",
    "# there are total 9 periods as nine class with name tombstone-container, so run for loop 9 times\n",
    "\n",
    "for i in range(9):\n",
    "    per = forecast_items[i]\n",
    "    period = per.find(class_=\"period-name\")\n",
    "    short_desc = per.find(class_=\"short-desc\")\n",
    "    temperature = per.find(class_=\"temp\")\n",
    "    image = per.find(\"img\")\n",
    "    desc = image['title']\n",
    "    print(period.get_text())\n",
    "    print(short_desc.get_text())\n",
    "    print(temperature.get_text())\n",
    "    print(desc)\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Grabbing Title of webpage (Udemy Video) using select method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = requests.get('https://www.example.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<html>\\n    <head>\\n        <title>A simple example page</title>\\n    </head>\\n    <body>\\n        <p>Here is some simple content for this page.</p>\\n    </body>\\n</html>'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "\n",
       "<html>\n",
       "<head>\n",
       "<title>A simple example page</title>\n",
       "</head>\n",
       "<body>\n",
       "<p>Here is some simple content for this page.</p>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to grab title of page\n",
    "\n",
    "a = soup.select('title')  #pass title tag, if we want paragraph pass 'p'\n",
    "\n",
    "#so for select method, we need to pass tag name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>A simple example page</title>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a  # returns the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>A simple example page</title>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A simple example page'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].getText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Grabbing class of webpage (Udemy Video) using select method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let say from https://en.wikipedia.org/wiki/Jonas_Salk website, we need to grab all points from contents like \n",
    "\t\n",
    "    Early life and education\n",
    "\tPolio research....etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "\n",
    "<thead >\n",
    "<tr>\n",
    "<th>\n",
    "<p>Syntax to pass to the .select() method</p>\n",
    "</th>\n",
    "<th>\n",
    "<p>Match Results</p>\n",
    "</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>\n",
    "<p><code>soup.select('div')</code></p>\n",
    "</td>\n",
    "<td>\n",
    "<p>All elements with the <code>&lt;div&gt;</code> tag</p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "<p><code>soup.select('#some_id')</code></p>\n",
    "</td>\n",
    "<td>\n",
    "<p>The HTML element containing the <code>id</code> attribute of <code>some_id</code></p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "<p><code>soup.select('.notice')</code></p>\n",
    "</td>\n",
    "<td>\n",
    "<p>All the HTML elements with the CSS <code>class</code> named <code>notice</code></p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "<p><code>soup.select('div span')</code></p>\n",
    "</td>\n",
    "<td>\n",
    "<p>Any elements named <code>&lt;span&gt;</code> that are within an element named <code>&lt;div&gt;</code></p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "<p><code>soup.select('div &gt; span')</code></p>\n",
    "</td>\n",
    "<td>\n",
    "<p>Any elements named <code class=\"literal2\">&lt;span&gt;</code> that are <span><em >directly</em></span> within an element named <code class=\"literal2\">&lt;div&gt;</code>, with no other element in between</p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get('https://en.wikipedia.org/wiki/Jonas_Salk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"toctext\">Early life and education</span>,\n",
       " <span class=\"toctext\">Education</span>,\n",
       " <span class=\"toctext\">Medical school</span>,\n",
       " <span class=\"toctext\">Postgraduate research and early laboratory work</span>,\n",
       " <span class=\"toctext\">Polio research</span>,\n",
       " <span class=\"toctext\">Becoming a public figure</span>,\n",
       " <span class=\"toctext\">Celebrity versus privacy</span>,\n",
       " <span class=\"toctext\">Maintaining his individuality</span>,\n",
       " <span class=\"toctext\">Establishing the Salk Institute</span>,\n",
       " <span class=\"toctext\">AIDS vaccine work</span>,\n",
       " <span class=\"toctext\">Salk's \"biophilosophy\"</span>,\n",
       " <span class=\"toctext\">Personal life</span>,\n",
       " <span class=\"toctext\">Honors and recognition</span>,\n",
       " <span class=\"toctext\">Documentary films</span>,\n",
       " <span class=\"toctext\">Salk's book publications</span>,\n",
       " <span class=\"toctext\">See also</span>,\n",
       " <span class=\"toctext\">References</span>,\n",
       " <span class=\"toctext\">Further reading</span>,\n",
       " <span class=\"toctext\">External links</span>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select('.toctext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_line = soup.select('.toctext')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Early life and education'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_line.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early life and education\n",
      "Education\n",
      "Medical school\n",
      "Postgraduate research and early laboratory work\n",
      "Polio research\n",
      "Becoming a public figure\n",
      "Celebrity versus privacy\n",
      "Maintaining his individuality\n",
      "Establishing the Salk Institute\n",
      "AIDS vaccine work\n",
      "Salk's \"biophilosophy\"\n",
      "Personal life\n",
      "Honors and recognition\n",
      "Documentary films\n",
      "Salk's book publications\n",
      "See also\n",
      "References\n",
      "Further reading\n",
      "External links\n"
     ]
    }
   ],
   "source": [
    "# now to grab only text from all of the above\n",
    "\n",
    "for i in soup.select('.toctext'):\n",
    "    print(i.text)  #.text will print only text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Grabbing image from webpage (Udemy Video) using select method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's grab APJ Abdul Kalam Image from site 'https://en.wikipedia.org/wiki/A._P._J._Abdul_Kalam'\n",
    "\n",
    "# go over the image and right click to inspect the element, to get any class or id associated with image\n",
    "\n",
    "# Here we will grab the image using img tag, but there are many images are available but we are intersted in specific image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = requests.get('https://en.wikipedia.org/wiki/A._P._J._Abdul_Kalam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(i.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = soup.select('img')  #selected img tag from soup object\n",
    "#all_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<img alt=\"A. P. J. Abdul Kalam.jpg\" data-file-height=\"2953\" data-file-width=\"2497\" decoding=\"async\" height=\"260\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/6e/A._P._J._Abdul_Kalam.jpg/220px-A._P._J._Abdul_Kalam.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/6e/A._P._J._Abdul_Kalam.jpg/330px-A._P._J._Abdul_Kalam.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/6e/A._P._J._Abdul_Kalam.jpg/440px-A._P._J._Abdul_Kalam.jpg 2x\" width=\"220\"/>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using trials, we need to identify the index of above where actual image is present, in here it is at index 2\n",
    "specific_image = all_images[2]\n",
    "specific_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'//upload.wikimedia.org/wikipedia/commons/thumb/6/6e/A._P._J._Abdul_Kalam.jpg/220px-A._P._J._Abdul_Kalam.jpg'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now from above, we only want image link which is present is src tag\n",
    "\n",
    "# now all_images[2] will act as dictionary, from this dict we can grab the keys like src etc..\n",
    "\n",
    "specific_image['src'] # this is how we will get the link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now to grab this image we need to access image url using requests.get\n",
    "# for that copy above link and place https before it\n",
    "\n",
    "act_image = requests.get('https://upload.wikimedia.org/wikipedia/commons/thumb/6/6e/A._P._J._Abdul_Kalam.jpg/220px-A._P._J._Abdul_Kalam.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# act_image.content # this will give binary code of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13133"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use above code to save/download this image to our local system using file handling method\n",
    "\n",
    "f = open(r'abdul_kalam_image.jpg','wb') #extension must same as that of link we accesses jpg or png\n",
    "f.write(act_image.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note** : Using Markdown option we can use HTML tags and print the results, see below image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"A. P. J. Abdul Kalam.jpg\" data-file-height=\"2953\" data-file-width=\"2497\" decoding=\"async\" height=\"260\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/6e/A._P._J._Abdul_Kalam.jpg/220px-A._P._J._Abdul_Kalam.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/6e/A._P._J._Abdul_Kalam.jpg/330px-A._P._J._Abdul_Kalam.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/6e/A._P._J._Abdul_Kalam.jpg/440px-A._P._J._Abdul_Kalam.jpg 2x\" width=\"220\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
